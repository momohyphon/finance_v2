import requests
from bs4 import BeautifulSoup
from urllib.parse import quote_plus
from datetime import datetime
import firebase_admin
from firebase_admin import credentials, firestore
import time
import os
import sys

JSON_PATH = r"c:\Users\gwak\Finance_Final_V2\serviceAccountKey.json"

# 1. íŒŒì´ì–´ë² ì´ìŠ¤ ì—°ê²°
if not firebase_admin._apps:
    try:
        if os.path.exists(JSON_PATH):
            cred = credentials.Certificate(JSON_PATH)
            firebase_admin.initialize_app(cred)
            print("ë¯¸êµ­ë‰´ìŠ¤: íŒŒì´ì–´ë² ì´ìŠ¤ ì¸ì¦ ì„±ê³µ")
        else:
            cred = credentials.Certificate("serviceAccountKey.JSON")
            firebase_admin.initialize_app(cred)
    except Exception as e:
        print(f"íŒŒì´ì–´ë² ì´ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        
db = firestore.client()


    
# 2. ë¯¸êµ­ ì£¼ì‹ ë­í‚¹ ë°ì´í„°ì—ì„œ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸° (ì˜¤ë¹ ì˜ USìš© latest ê²½ë¡œ í™•ì¸)
doc = db.collection('rs_data').document('us_latest').get() 
if not doc.exists:
    print("âŒ ë¯¸êµ­ ë­í‚¹ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    sys.exit()

rankings = doc.to_dict().get('rankings', [])
now_str = datetime.now().strftime('%Y-%m-%d %H:%M')

# ğŸ“¢ [í•µì‹¬] news_us ë¬¸ì„œ í•˜ë‚˜ì— ë‹¤ ì§‘ì–´ë„£ì„ ë”•ì…”ë„ˆë¦¬
fields_to_add = {}

print(f"ğŸ‡ºğŸ‡¸ ë¯¸êµ­ ë‰´ìŠ¤ ê²€ìƒ‰ ì‹œì‘ ({len(rankings)}ê°œ ì¢…ëª©)")

for item in rankings:
    # ë¯¸êµ­ ë°ì´í„° í•„ë“œëª…ì— ë§ì¶° ticker ë˜ëŠ” code ì‚¬ìš©
    code = item.get('code') or item.get('ticker')
    name = item['name']
    
    # ğŸ“¢ [í•„í„° í‘œì‹œ] í•„ë“œ ì´ë¦„ì„ 'ì¢…ëª©ì½”ë“œ_ì¢…ëª©ëª…'ìœ¼ë¡œ ì„¤ì •
    field_key = f"{code}_{name}"
    
    try:
        # ë¯¸êµ­ ë‰´ìŠ¤ìš© RSS (ì–¸ì–´: en-US, ì§€ì—­: US)
        url = f"https://news.google.com/rss/search?q={quote_plus(name)}&hl=en-US&gl=US&ceid=US:en"
        res = requests.get(url, timeout=10)
        soup = BeautifulSoup(res.content, "xml")
        items = soup.find_all("item")[:20]

        articles = []
        for i in items:
            articles.append({
                "title": i.title.text,
                "link": i.link.text,
                "publisher": i.source.text if i.source else "Google News",
                "time": i.pubDate.text
            })

        # ğŸ“¢ ë”•ì…”ë„ˆë¦¬ì— í•„ë“œëª…ìœ¼ë¡œ ë°ì´í„° ì €ì¥
        fields_to_add[field_key] = {
            "update_time": now_str,
            "articles": articles
        }
        
        print(f"âœ… í•„ë“œ ì¤€ë¹„: {field_key}")
        time.sleep(0.3) # ì°¨ë‹¨ ë°©ì§€

    except Exception as e:
        print(f"âŒ {name} ë‰´ìŠ¤ ì—ëŸ¬: {e}")

# ==========================================================
# ğŸ“¢ [ìµœì¢… ë°˜ì˜] stock_news ì»¬ë ‰ì…˜ -> 'news_us' ë¬¸ì„œ ë”± í•˜ë‚˜ì— ëª¨ë“  í•„ë“œ ê½‚ê¸°
# ==========================================================
db.collection('stock_news').document('news_us').set(fields_to_add)
print(f"ğŸš€ [ì™„ë£Œ] news_us ë¬¸ì„œì— ëª¨ë“  ë¯¸êµ­ ì¢…ëª© í•„ë“œê°€ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤!")


    